#material
#localsize 16 16
#compute
///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Edge detection and local contrast adaptation helpers
///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//
lpfloat GetActualEdgeThreshold( )
{
    lpfloat retVal = g_CMAA2_EdgeThreshold;
    return retVal;
}
//
lpfloat EdgeDetectColorCalcDiff( lpfloat3 colorA, lpfloat3 colorB )
{
    const lpfloat3 LumWeights = lpfloat3( 0.299, 0.587, 0.114 );
    lpfloat3 diff = abs( (colorA.rgb - colorB.rgb) );
    return dot( diff.rgb, LumWeights.rgb );
}
//
// apply custom curve / processing to put input color (linear) in the format required by ComputeEdge
lpfloat3 ProcessColorForEdgeDetect( lpfloat3 color )
{
    //pixelColors[i] = LINEAR_to_SRGB( pixelColors[i] );            // correct reference
    //pixelColors[i] = pow( max( 0, pixelColors[i], 1.0 / 2.4 ) );  // approximate sRGB curve
    return sqrt( color ); // just very roughly approximate RGB curve
}
//
lpfloat2 ComputeEdge( int x, int y, lpfloat3 pixelColors[3 * 3 - 1] )
{
    lpfloat2 temp;
    temp.x = EdgeDetectColorCalcDiff( pixelColors[x + y * 3].rgb, pixelColors[x + 1 + y * 3].rgb );
    temp.y = EdgeDetectColorCalcDiff( pixelColors[x + y * 3].rgb, pixelColors[x + ( y + 1 ) * 3].rgb );
    return temp;    // for HDR edge detection it might be good to premultiply both of these by some factor - otherwise clamping to 1 might prevent some local contrast adaptation. It's a very minor nitpick though, unlikely to significantly affect things.
}                                     
// color -> log luma-for-edges conversion
float RGBToLumaForEdges( float3 linearRGB )
{
#if 0
    // this matches Miniengine luma path
    float Luma = dot( linearRGB, float3(0.212671, 0.715160, 0.072169) );
    return log2(1 + Luma * 15) / 4;
#else
    // this is what original FXAA (and consequently CMAA2) use by default - these coefficients correspond to Rec. 601 and those should be
    // used on gamma-compressed components (see https://en.wikipedia.org/wiki/Luma_(video)#Rec._601_luma_versus_Rec._709_luma_coefficients), 
    float luma = dot( sqrt( linearRGB.rgb ), float3( 0.299, 0.587, 0.114 ) );  // http://en.wikipedia.org/wiki/CCIR_601
    // using sqrt luma for now but log luma like in miniengine provides a nicer curve on the low-end
    return luma;
#endif
}
lpfloat2 ComputeEdgeLuma( int x, int y, lpfloat pixelLumas[3 * 3 - 1] )
{
    lpfloat2 temp;
    temp.x = abs( pixelLumas[x + y * 3] - pixelLumas[x + 1 + y * 3] );
    temp.y = abs( pixelLumas[x + y * 3] - pixelLumas[x + ( y + 1 ) * 3] );
    return temp;    // for HDR edge detection it might be good to premultiply both of these by some factor - otherwise clamping to 1 might prevent some local contrast adaptation. It's a very minor nitpick though, unlikely to significantly affect things.
}
//
lpfloat ComputeLocalContrastV( int x, int y, in lpfloat2 neighbourhood[4][4] )
{
    // new, small kernel 4-connecting-edges-only local contrast adaptation
    return max( max( neighbourhood[x + 1][y + 0].y, neighbourhood[x + 1][y + 1].y ), max( neighbourhood[x + 2][y + 0].y, neighbourhood[x + 2][y + 1].y ) ) * lpfloat( g_CMAA2_LocalContrastAdaptationAmount );

//    // slightly bigger kernel that enhances edges in-line (not worth the cost)
//  return ( max( max( neighbourhood[x + 1][y + 0].y, neighbourhood[x + 1][y + 1].y ), max( neighbourhood[x + 2][y + 0].y, neighbourhood[x + 2][y + 1].y ) ) 
//        - ( neighbourhood[x + 1][y + 0].x + neighbourhood[x + 1][y + 2].x ) * 0.3 ) * lpfloat( g_CMAA2_LocalContrastAdaptationAmount );
}
//
lpfloat ComputeLocalContrastH( int x, int y, in lpfloat2 neighbourhood[4][4] )
{
    // new, small kernel 4-connecting-edges-only local contrast adaptation
    return max( max( neighbourhood[x + 0][y + 1].x, neighbourhood[x + 1][y + 1].x ), max( neighbourhood[x + 0][y + 2].x, neighbourhood[x + 1][y + 2].x ) ) * lpfloat( g_CMAA2_LocalContrastAdaptationAmount );

//    // slightly bigger kernel that enhances edges in-line (not worth the cost)
//    return ( max( max( neighbourhood[x + 0][y + 1].x, neighbourhood[x + 1][y + 1].x ), max( neighbourhood[x + 0][y + 2].x, neighbourhood[x + 1][y + 2].x ) ) 
//        - ( neighbourhood[x + 0][y + 1].y + neighbourhood[x + 2][y + 1].y ) * 0.3 ) * lpfloat( g_CMAA2_LocalContrastAdaptationAmount );
}
///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////

lpfloat4 ComputeSimpleShapeBlendValues( lpfloat4 edges, lpfloat4 edgesLeft, lpfloat4 edgesRight, lpfloat4 edgesTop, lpfloat4 edgesBottom, uniform bool dontTestShapeValidity )
{
    // a 3x3 kernel for higher quality handling of L-based shapes (still rather basic and conservative)

    lpfloat fromRight   = edges.r;
    lpfloat fromBelow   = edges.g;
    lpfloat fromLeft    = edges.b;
    lpfloat fromAbove   = edges.a;

    lpfloat blurCoeff = lpfloat( g_CMAA2_SimpleShapeBlurinessAmount );

    lpfloat numberOfEdges = dot( edges, lpfloat4( 1, 1, 1, 1 ) );

    lpfloat numberOfEdgesAllAround = dot(edgesLeft.bga + edgesRight.rga + edgesTop.rba + edgesBottom.rgb, lpfloat3( 1, 1, 1 ) );

    // skip if already tested for before calling this function
    if( !dontTestShapeValidity )
    {
        // No blur for straight edge
        if( numberOfEdges == 1 )
            blurCoeff = 0;

        // L-like step shape ( only blur if it's a corner, not if it's two parallel edges)
        if( numberOfEdges == 2 )
            blurCoeff *= ( ( lpfloat(1.0) - fromBelow * fromAbove ) * ( lpfloat(1.0) - fromRight * fromLeft ) );
    }

    // L-like step shape
    //[branch]
    if( numberOfEdges == 2 )
    {
        blurCoeff *= 0.75;

#if 1
        float k = 0.9f;
#if 0
        fromRight   += k * (edges.g * edgesTop.r +      edges.a * edgesBottom.r );
        fromBelow   += k * (edges.r * edgesLeft.g +     edges.b * edgesRight.g );
        fromLeft    += k * (edges.g * edgesTop.b +      edges.a * edgesBottom.b );
        fromAbove   += k * (edges.b * edgesRight.a +    edges.r * edgesLeft.a );
#else
        fromRight   += k * (edges.g * edgesTop.r     * (1.0-edgesLeft.g)   +     edges.a * edgesBottom.r   * (1.0-edgesLeft.a)      );
        fromBelow   += k * (edges.b * edgesRight.g   * (1.0-edgesTop.b)    +     edges.r * edgesLeft.g     * (1.0-edgesTop.r)       );
        fromLeft    += k * (edges.a * edgesBottom.b  * (1.0-edgesRight.a)  +     edges.g * edgesTop.b      * (1.0-edgesRight.g)     );
        fromAbove   += k * (edges.r * edgesLeft.a    * (1.0-edgesBottom.r) +     edges.b * edgesRight.a   *  (1.0-edgesBottom.b)    );
#endif
#endif
    }

    // if( numberOfEdges == 3 )
    //     blurCoeff *= 0.95;

    // Dampen the blurring effect when lots of neighbouring edges - additionally preserves text and texture detail
#if CMAA2_EXTRA_SHARPNESS
    blurCoeff *= saturate( 1.15 - numberOfEdgesAllAround / 8.0 );
#else
    blurCoeff *= saturate( 1.30 - numberOfEdgesAllAround / 10.0 );
#endif

    return lpfloat4( fromLeft, fromAbove, fromRight, fromBelow ) * blurCoeff;
}

uint LoadEdge( int2 pixelPos, int2 offset, uint msaaSampleIndex )
{
#if CMAA_PACK_SINGLE_SAMPLE_EDGE_TO_HALF_WIDTH
    uint a      = uint(pixelPos.x+offset.x) % 2;

#if CMAA2_EDGE_UNORM
    uint edge   = (uint)(g_workingEdges.Load( uint2( uint(pixelPos.x+offset.x)/2, pixelPos.y + offset.y ) ).x * 255.0 + 0.5);
#else    
    uint edge   = g_workingEdges.Load( uint2( uint(pixelPos.x+offset.x)/2, pixelPos.y + offset.y ) ).x;
#endif
    edge = (edge >> (a*4)) & 0xF;
#else
    uint edge   = g_workingEdges.Load( pixelPos + offset ).x;
#endif
    return edge;
}

groupshared lpfloat4 g_groupShared2x2FracEdgesH[CMAA2_CS_INPUT_KERNEL_SIZE_X * CMAA2_CS_INPUT_KERNEL_SIZE_Y];
groupshared lpfloat4 g_groupShared2x2FracEdgesV[CMAA2_CS_INPUT_KERNEL_SIZE_X * CMAA2_CS_INPUT_KERNEL_SIZE_Y];
// void GroupsharedLoadQuadH( uint addr, out lpfloat e00, out lpfloat e10, out lpfloat e01, out lpfloat e11 ) { lpfloat4 val = g_groupShared2x2FracEdgesH[addr]; e00 = val.x; e10 = val.y; e01 = val.z; e11 = val.w; }
// void GroupsharedLoadQuadV( uint addr, out lpfloat e00, out lpfloat e10, out lpfloat e01, out lpfloat e11 ) { lpfloat4 val = g_groupShared2x2FracEdgesV[addr]; e00 = val.x; e10 = val.y; e01 = val.z; e11 = val.w; }
void GroupsharedLoadQuadHV( uint addr, out lpfloat2 e00, out lpfloat2 e10, out lpfloat2 e01, out lpfloat2 e11 ) 
{ 
    lpfloat4 valH = g_groupShared2x2FracEdgesH[addr]; e00.y = valH.x; e10.y = valH.y; e01.y = valH.z; e11.y = valH.w; 
    lpfloat4 valV = g_groupShared2x2FracEdgesV[addr]; e00.x = valV.x; e10.x = valV.y; e01.x = valV.z; e11.x = valV.w; 
}

///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
// Edge detection compute shader
///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
//groupshared uint g_groupShared2x2ProcColors[(CMAA2_CS_INPUT_KERNEL_SIZE_X * 2 + 1) * (CMAA2_CS_INPUT_KERNEL_SIZE_Y * 2 + 1)];
//groupshared float3 g_groupSharedResolvedMSColors[(CMAA2_CS_INPUT_KERNEL_SIZE_X * 2 + 1) * (CMAA2_CS_INPUT_KERNEL_SIZE_Y * 2 + 1)];
//
[numthreads( CMAA2_CS_INPUT_KERNEL_SIZE_X, CMAA2_CS_INPUT_KERNEL_SIZE_Y, 1 )]
void EdgesColor2x2CS( uint3 groupID : SV_GroupID, uint3 groupThreadID : SV_GroupThreadID )
{
    // screen position in the input (expanded) kernel (shifted one 2x2 block up/left)
    uint2 pixelPos = groupID.xy * int2( CMAA2_CS_OUTPUT_KERNEL_SIZE_X, CMAA2_CS_OUTPUT_KERNEL_SIZE_Y ) + groupThreadID.xy - int2( 1, 1 );
    pixelPos *= int2( 2, 2 );

    const uint2 qeOffsets[4]        = { {0, 0}, {1, 0}, {0, 1}, {1, 1} };
    const uint rowStride2x2         = CMAA2_CS_INPUT_KERNEL_SIZE_X;
    const uint centerAddr2x2        = groupThreadID.x + groupThreadID.y * rowStride2x2;
    // const uint msaaSliceStride2x2   = CMAA2_CS_INPUT_KERNEL_SIZE_X * CMAA2_CS_INPUT_KERNEL_SIZE_Y;
    const bool inOutputKernel       = !any( bool4( groupThreadID.x == ( CMAA2_CS_INPUT_KERNEL_SIZE_X - 1 ), groupThreadID.x == 0, groupThreadID.y == ( CMAA2_CS_INPUT_KERNEL_SIZE_Y - 1 ), groupThreadID.y == 0 ) );

    uint i;
    lpfloat2 qe0, qe1, qe2, qe3;
    uint4 outEdges = { 0, 0, 0, 0 };

        {
            uint msaaSampleIndex = 0;

            // edge detection
#if CMAA2_EDGE_DETECTION_LUMA_PATH == 0
            lpfloat3 pixelColors[3 * 3 - 1];
            [unroll]
            for( i = 0; i < 3 * 3 - 1; i++ )
                pixelColors[i] = LoadSourceColor( pixelPos, int2( i % 3, i / 3 ), msaaSampleIndex ).rgb;

            [unroll]
            for( i = 0; i < 3 * 3 - 1; i++ )
                pixelColors[i] = ProcessColorForEdgeDetect( pixelColors[i] );

            qe0 = ComputeEdge( 0, 0, pixelColors );
            qe1 = ComputeEdge( 1, 0, pixelColors );
            qe2 = ComputeEdge( 0, 1, pixelColors );
            qe3 = ComputeEdge( 1, 1, pixelColors );
#else // CMAA2_EDGE_DETECTION_LUMA_PATH != 0
            lpfloat pixelLumas[3 * 3 - 1];
    #if CMAA2_EDGE_DETECTION_LUMA_PATH == 1 // compute in-place
            [unroll]
            for( i = 0; i < 3 * 3 - 1; i++ )
            {
                lpfloat3 color = LoadSourceColor( pixelPos, int2( i % 3, i / 3 ), msaaSampleIndex ).rgb;
                pixelLumas[i] = RGBToLumaForEdges( color );
            }
    #elif CMAA2_EDGE_DETECTION_LUMA_PATH == 2 // source from outside
    #if 0 // same as below, just without Gather
            [unroll]
            for( i = 0; i < 3 * 3 - 1; i++ )
                 pixelLumas[i] = g_inLumaReadonly.Load( int3( pixelPos, 0 ), int2( i % 3, i / 3 ) ).r;
    #else
            float2 texSize;
            g_inLumaReadonly.GetDimensions( texSize.x, texSize.y );
            float2 gatherUV = (float2(pixelPos) + float2( 0.5, 0.5 )) / texSize;
            float4 TL = g_inLumaReadonly.GatherRed( g_gather_point_clamp_Sampler, gatherUV );
            float4 TR = g_inLumaReadonly.GatherRed( g_gather_point_clamp_Sampler, gatherUV, int2( 1, 0 ) );
            float4 BL = g_inLumaReadonly.GatherRed( g_gather_point_clamp_Sampler, gatherUV, int2( 0, 1 ) );
            pixelLumas[0] = TL.w; pixelLumas[1] = TL.z; pixelLumas[2] = TR.z; pixelLumas[3] = TL.x;
            pixelLumas[4] = TL.y; pixelLumas[5] = TR.y; pixelLumas[6] = BL.x; pixelLumas[7] = BL.y;
    #endif
    #elif CMAA2_EDGE_DETECTION_LUMA_PATH == 3 // source in alpha channel of input color
            float2 texSize;
            g_inoutColorReadonly.GetDimensions( texSize.x, texSize.y );
            float2 gatherUV = (float2(pixelPos) + float2( 0.5, 0.5 )) / texSize;
            float4 TL = g_inoutColorReadonly.GatherAlpha( g_gather_point_clamp_Sampler, gatherUV );
            float4 TR = g_inoutColorReadonly.GatherAlpha( g_gather_point_clamp_Sampler, gatherUV, int2( 1, 0 ) );
            float4 BL = g_inoutColorReadonly.GatherAlpha( g_gather_point_clamp_Sampler, gatherUV, int2( 0, 1 ) );
            pixelLumas[0] = (lpfloat)TL.w; pixelLumas[1] = (lpfloat)TL.z; pixelLumas[2] = (lpfloat)TR.z; pixelLumas[3] = (lpfloat)TL.x; 
            pixelLumas[4] = (lpfloat)TL.y; pixelLumas[5] = (lpfloat)TR.y; pixelLumas[6] = (lpfloat)BL.x; pixelLumas[7] = (lpfloat)BL.y;                 
    #endif
            qe0 = ComputeEdgeLuma( 0, 0, pixelLumas );
            qe1 = ComputeEdgeLuma( 1, 0, pixelLumas );
            qe2 = ComputeEdgeLuma( 0, 1, pixelLumas );
            qe3 = ComputeEdgeLuma( 1, 1, pixelLumas );
#endif

            g_groupShared2x2FracEdgesV[centerAddr2x2 + rowStride2x2 * 0] = lpfloat4( qe0.x, qe1.x, qe2.x, qe3.x );
            g_groupShared2x2FracEdgesH[centerAddr2x2 + rowStride2x2 * 0] = lpfloat4( qe0.y, qe1.y, qe2.y, qe3.y );

        GroupMemoryBarrierWithGroupSync( );

        [branch]
        if( inOutputKernel )
        {
            lpfloat2 topRow         = g_groupShared2x2FracEdgesH[ centerAddr2x2 - rowStride2x2 ].zw;   // top row's bottom edge
            lpfloat2 leftColumn     = g_groupShared2x2FracEdgesV[ centerAddr2x2 - 1 ].yw;              // left column's right edge

            bool someNonZeroEdges = any( lpfloat4( qe0, qe1 ) + lpfloat4( qe2, qe3 ) + lpfloat4( topRow[0], topRow[1], leftColumn[0], leftColumn[1] ) );
            //bool someNonZeroEdges = packedCenterEdges.x | packedCenterEdges.y | (packedQuadP0M1.y & 0xFFFF0000) | (packedQuadM1P0.x & 0xFF00FF00);

            [branch]
            if( someNonZeroEdges )
            {
                // Clear deferred color list heads to empty (if potentially needed - even though some edges might get culled by local contrast adaptation 
                // step below, it's still cheaper to just clear it without additional logic)
                g_workingDeferredBlendItemListHeads[ uint2( pixelPos ) / 2 ] = 0xFFFFFFFF;

                lpfloat4 ce[4];

            #if 1 // local contrast adaptation
                lpfloat2 dummyd0, dummyd1, dummyd2;
                lpfloat2 neighbourhood[4][4];

                ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
                // load & unpack kernel data from SLM
                GroupsharedLoadQuadHV( centerAddr2x2 - rowStride2x2 - 1 , dummyd0, dummyd1, dummyd2, neighbourhood[0][0] );
                GroupsharedLoadQuadHV( centerAddr2x2 - rowStride2x2     , dummyd0, dummyd1, neighbourhood[1][0], neighbourhood[2][0] );
                GroupsharedLoadQuadHV( centerAddr2x2 - rowStride2x2 + 1 , dummyd0, dummyd1, neighbourhood[3][0], dummyd2 );
                GroupsharedLoadQuadHV( centerAddr2x2 - 1                , dummyd0, neighbourhood[0][1], dummyd1, neighbourhood[0][2] );
                GroupsharedLoadQuadHV( centerAddr2x2 + 1                , neighbourhood[3][1], dummyd0, neighbourhood[3][2], dummyd1 );
                GroupsharedLoadQuadHV( centerAddr2x2 - 1 + rowStride2x2 , dummyd0, neighbourhood[0][3], dummyd1, dummyd2 );
                GroupsharedLoadQuadHV( centerAddr2x2 + rowStride2x2     , neighbourhood[1][3], neighbourhood[2][3], dummyd0, dummyd1 );
                neighbourhood[1][0].y = topRow[0]; // already in registers
                neighbourhood[2][0].y = topRow[1]; // already in registers
                neighbourhood[0][1].x = leftColumn[0]; // already in registers
                neighbourhood[0][2].x = leftColumn[1]; // already in registers
                neighbourhood[1][1] = qe0; // already in registers
                neighbourhood[2][1] = qe1; // already in registers
                neighbourhood[1][2] = qe2; // already in registers
                neighbourhood[2][2] = qe3; // already in registers
                ////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
        
                topRow[0]     = ( topRow[0]     - ComputeLocalContrastH( 0, -1, neighbourhood ) ) > GetActualEdgeThreshold();
                topRow[1]     = ( topRow[1]     - ComputeLocalContrastH( 1, -1, neighbourhood ) ) > GetActualEdgeThreshold();
                leftColumn[0] = ( leftColumn[0] - ComputeLocalContrastV( -1, 0, neighbourhood ) ) > GetActualEdgeThreshold();
                leftColumn[1] = ( leftColumn[1] - ComputeLocalContrastV( -1, 1, neighbourhood ) ) > GetActualEdgeThreshold();

                ce[0].x = ( qe0.x - ComputeLocalContrastV( 0, 0, neighbourhood ) ) > GetActualEdgeThreshold();
                ce[0].y = ( qe0.y - ComputeLocalContrastH( 0, 0, neighbourhood ) ) > GetActualEdgeThreshold();
                ce[1].x = ( qe1.x - ComputeLocalContrastV( 1, 0, neighbourhood ) ) > GetActualEdgeThreshold();
                ce[1].y = ( qe1.y - ComputeLocalContrastH( 1, 0, neighbourhood ) ) > GetActualEdgeThreshold();
                ce[2].x = ( qe2.x - ComputeLocalContrastV( 0, 1, neighbourhood ) ) > GetActualEdgeThreshold();
                ce[2].y = ( qe2.y - ComputeLocalContrastH( 0, 1, neighbourhood ) ) > GetActualEdgeThreshold();
                ce[3].x = ( qe3.x - ComputeLocalContrastV( 1, 1, neighbourhood ) ) > GetActualEdgeThreshold();
                ce[3].y = ( qe3.y - ComputeLocalContrastH( 1, 1, neighbourhood ) ) > GetActualEdgeThreshold();
            #else
                topRow[0]     = topRow[0]    > GetActualEdgeThreshold();
                topRow[1]     = topRow[1]    > GetActualEdgeThreshold();
                leftColumn[0] = leftColumn[0]> GetActualEdgeThreshold();
                leftColumn[1] = leftColumn[1]> GetActualEdgeThreshold();
                ce[0].x = qe0.x > GetActualEdgeThreshold();
                ce[0].y = qe0.y > GetActualEdgeThreshold();
                ce[1].x = qe1.x > GetActualEdgeThreshold();
                ce[1].y = qe1.y > GetActualEdgeThreshold();
                ce[2].x = qe2.x > GetActualEdgeThreshold();
                ce[2].y = qe2.y > GetActualEdgeThreshold();
                ce[3].x = qe3.x > GetActualEdgeThreshold();
                ce[3].y = qe3.y > GetActualEdgeThreshold();
            #endif

                //left
                ce[0].z = leftColumn[0];
                ce[1].z = ce[0].x;
                ce[2].z = leftColumn[1];
                ce[3].z = ce[2].x;

                // top
                ce[0].w = topRow[0];
                ce[1].w = topRow[1];
                ce[2].w = ce[0].y;
                ce[3].w = ce[1].y;

                [unroll]
                for( i = 0; i < 4; i++ )
                {
                    const uint2 localPixelPos = pixelPos + qeOffsets[i];

                    const lpfloat4 edges = ce[i];

                    // if there's at least one two edge corner, this is a candidate for simple or complex shape processing...
                    bool isCandidate = ( edges.x * edges.y + edges.y * edges.z + edges.z * edges.w + edges.w * edges.x ) != 0;
                    if( isCandidate )
                    {
                        uint counterIndex;  g_workingControlBuffer.InterlockedAdd( 4*4, 1, counterIndex );
                        g_workingShapeCandidates[counterIndex] = (localPixelPos.x << 18) | (msaaSampleIndex << 14) | localPixelPos.y;
                    }

                    // Write out edges - we write out all, including empty pixels, to make sure shape detection edge tracing
                    // doesn't continue on previous frame's edges that no longer exist.
                    uint packedEdge = PackEdges( edges );
                    outEdges[i] = packedEdge;
                }
            }
        }
    }

    // finally, write the edges!
    [branch]
    if( inOutputKernel )
    {
#if CMAA_PACK_SINGLE_SAMPLE_EDGE_TO_HALF_WIDTH
#if CMAA2_EDGE_UNORM
        g_workingEdges[ int2(pixelPos.x/2, pixelPos.y+0) ] = ((outEdges[1] << 4) | outEdges[0]) / 255.0;
        g_workingEdges[ int2(pixelPos.x/2, pixelPos.y+1) ] = ((outEdges[3] << 4) | outEdges[2]) / 255.0;        
#else
        g_workingEdges[ int2(pixelPos.x/2, pixelPos.y+0) ] = (outEdges[1] << 4) | outEdges[0];
        g_workingEdges[ int2(pixelPos.x/2, pixelPos.y+1) ] = (outEdges[3] << 4) | outEdges[2];
#endif
#else
        {
            [unroll] for( uint i = 0; i < 4; i++ )
            g_workingEdges[pixelPos + qeOffsets[i]] = outEdges[i];
        }
#endif
    }
}
///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////